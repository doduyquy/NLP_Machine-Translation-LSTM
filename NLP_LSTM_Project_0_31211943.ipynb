{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1Y5-hTNuMCR",
        "outputId": "5760e8a5-362c-4767-eda7-83bf9c0a67f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (3.8.11)\n",
            "Requirement already satisfied: nltk in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (3.9.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\dang khoa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (2.12.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dang khoa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.32.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in c:\\users\\dang khoa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (65.5.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\dang khoa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: joblib in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: click in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\dang khoa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dang khoa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dang khoa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dang khoa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dang khoa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dang khoa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in c:\\users\\dang khoa\\appdata\\roaming\\python\\python310\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "     --------------------------------------- 0.1/12.8 MB 825.8 kB/s eta 0:00:16\n",
            "     --------------------------------------- 0.1/12.8 MB 751.6 kB/s eta 0:00:17\n",
            "     --------------------------------------- 0.1/12.8 MB 751.6 kB/s eta 0:00:17\n",
            "     --------------------------------------- 0.1/12.8 MB 751.6 kB/s eta 0:00:17\n",
            "     --------------------------------------- 0.1/12.8 MB 481.4 kB/s eta 0:00:27\n",
            "      -------------------------------------- 0.2/12.8 MB 726.5 kB/s eta 0:00:18\n",
            "      -------------------------------------- 0.3/12.8 MB 842.9 kB/s eta 0:00:15\n",
            "      -------------------------------------- 0.3/12.8 MB 846.5 kB/s eta 0:00:15\n",
            "     - ------------------------------------- 0.3/12.8 MB 807.1 kB/s eta 0:00:16\n",
            "     - ------------------------------------- 0.4/12.8 MB 782.8 kB/s eta 0:00:16\n",
            "     - ------------------------------------- 0.5/12.8 MB 829.2 kB/s eta 0:00:15\n",
            "     - ------------------------------------- 0.5/12.8 MB 874.6 kB/s eta 0:00:15\n",
            "     - ------------------------------------- 0.5/12.8 MB 819.2 kB/s eta 0:00:15\n",
            "     - ------------------------------------- 0.6/12.8 MB 885.1 kB/s eta 0:00:14\n",
            "     - ------------------------------------- 0.7/12.8 MB 917.7 kB/s eta 0:00:14\n",
            "     -- ------------------------------------ 0.7/12.8 MB 969.4 kB/s eta 0:00:13\n",
            "     -- ------------------------------------- 0.8/12.8 MB 1.0 MB/s eta 0:00:12\n",
            "     -- ------------------------------------- 0.9/12.8 MB 1.1 MB/s eta 0:00:12\n",
            "     --- ------------------------------------ 1.0/12.8 MB 1.1 MB/s eta 0:00:11\n",
            "     --- ------------------------------------ 1.0/12.8 MB 1.1 MB/s eta 0:00:11\n",
            "     --- ------------------------------------ 1.1/12.8 MB 1.1 MB/s eta 0:00:11\n",
            "     --- ------------------------------------ 1.2/12.8 MB 1.2 MB/s eta 0:00:10\n",
            "     --- ------------------------------------ 1.3/12.8 MB 1.2 MB/s eta 0:00:10\n",
            "     ---- ----------------------------------- 1.4/12.8 MB 1.2 MB/s eta 0:00:10\n",
            "     ---- ----------------------------------- 1.4/12.8 MB 1.2 MB/s eta 0:00:10\n",
            "     ---- ----------------------------------- 1.5/12.8 MB 1.2 MB/s eta 0:00:10\n",
            "     ---- ----------------------------------- 1.5/12.8 MB 1.2 MB/s eta 0:00:10\n",
            "     ----- ---------------------------------- 1.6/12.8 MB 1.2 MB/s eta 0:00:09\n",
            "     ----- ---------------------------------- 1.8/12.8 MB 1.3 MB/s eta 0:00:09\n",
            "     ----- ---------------------------------- 1.9/12.8 MB 1.3 MB/s eta 0:00:09\n",
            "     ------ --------------------------------- 2.0/12.8 MB 1.4 MB/s eta 0:00:08\n",
            "     ------ --------------------------------- 2.1/12.8 MB 1.4 MB/s eta 0:00:08\n",
            "     ------- -------------------------------- 2.3/12.8 MB 1.5 MB/s eta 0:00:08\n",
            "     ------- -------------------------------- 2.3/12.8 MB 1.5 MB/s eta 0:00:08\n",
            "     ------- -------------------------------- 2.4/12.8 MB 1.5 MB/s eta 0:00:08\n",
            "     ------- -------------------------------- 2.5/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     -------- ------------------------------- 2.6/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     -------- ------------------------------- 2.7/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     -------- ------------------------------- 2.7/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     -------- ------------------------------- 2.8/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     -------- ------------------------------- 2.8/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     -------- ------------------------------- 2.9/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     --------- ------------------------------ 3.0/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     --------- ------------------------------ 3.0/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     --------- ------------------------------ 3.1/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     --------- ------------------------------ 3.2/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     ---------- ----------------------------- 3.3/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     ---------- ----------------------------- 3.4/12.8 MB 1.5 MB/s eta 0:00:07\n",
            "     ----------- ---------------------------- 3.6/12.8 MB 1.6 MB/s eta 0:00:06\n",
            "     ----------- ---------------------------- 3.7/12.8 MB 1.6 MB/s eta 0:00:06\n",
            "     ------------ --------------------------- 3.9/12.8 MB 1.6 MB/s eta 0:00:06\n",
            "     ------------ --------------------------- 4.0/12.8 MB 1.7 MB/s eta 0:00:06\n",
            "     ------------- -------------------------- 4.2/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 4.4/12.8 MB 1.8 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 4.4/12.8 MB 1.8 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.8 MB/s eta 0:00:05\n",
            "     --------------- ------------------------ 4.9/12.8 MB 1.9 MB/s eta 0:00:05\n",
            "     --------------- ------------------------ 5.1/12.8 MB 1.9 MB/s eta 0:00:05\n",
            "     ---------------- ----------------------- 5.3/12.8 MB 1.9 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 5.6/12.8 MB 2.0 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 5.7/12.8 MB 2.0 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 5.9/12.8 MB 2.0 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 6.0/12.8 MB 2.1 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 6.3/12.8 MB 2.1 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 6.4/12.8 MB 2.1 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 6.5/12.8 MB 2.1 MB/s eta 0:00:03\n",
            "     -------------------- ------------------- 6.6/12.8 MB 2.1 MB/s eta 0:00:03\n",
            "     --------------------- ------------------ 6.9/12.8 MB 2.2 MB/s eta 0:00:03\n",
            "     --------------------- ------------------ 6.9/12.8 MB 2.2 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 7.1/12.8 MB 2.2 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 7.4/12.8 MB 2.2 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 7.5/12.8 MB 2.2 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 7.5/12.8 MB 2.2 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 7.6/12.8 MB 2.2 MB/s eta 0:00:03\n",
            "     ------------------------ --------------- 7.8/12.8 MB 2.2 MB/s eta 0:00:03\n",
            "     ------------------------ --------------- 7.9/12.8 MB 2.2 MB/s eta 0:00:03\n",
            "     ------------------------- -------------- 8.0/12.8 MB 2.2 MB/s eta 0:00:03\n",
            "     ------------------------- -------------- 8.1/12.8 MB 2.3 MB/s eta 0:00:03\n",
            "     ------------------------- -------------- 8.3/12.8 MB 2.3 MB/s eta 0:00:03\n",
            "     -------------------------- ------------- 8.4/12.8 MB 2.3 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 8.4/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 8.4/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 8.5/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 8.6/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 8.6/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 8.7/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 8.8/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 8.9/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 9.0/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 9.1/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 9.2/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 9.3/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 9.5/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 9.6/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 9.7/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 9.8/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 9.8/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 9.9/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 10.1/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 10.2/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 10.3/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 10.4/12.8 MB 2.3 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 10.4/12.8 MB 2.3 MB/s eta 0:00:02\n",
            "     --------------------------------- ------ 10.6/12.8 MB 2.4 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 10.9/12.8 MB 2.5 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 11.0/12.8 MB 2.5 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 11.3/12.8 MB 2.5 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 11.4/12.8 MB 2.6 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 11.5/12.8 MB 2.6 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 11.5/12.8 MB 2.6 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 11.5/12.8 MB 2.6 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 11.7/12.8 MB 2.5 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 11.7/12.8 MB 2.5 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 11.9/12.8 MB 2.6 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 12.0/12.8 MB 2.6 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 12.1/12.8 MB 2.6 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 12.3/12.8 MB 2.6 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.5/12.8 MB 2.6 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.8 MB 2.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.8 MB 2.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 12.8/12.8 MB 2.6 MB/s eta 0:00:00\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
            "     --------------------------------------- 0.1/16.3 MB 525.1 kB/s eta 0:00:31\n",
            "     --------------------------------------- 0.1/16.3 MB 655.4 kB/s eta 0:00:25\n",
            "     ---------------------------------------- 0.2/16.3 MB 1.1 MB/s eta 0:00:15\n",
            "      --------------------------------------- 0.3/16.3 MB 1.5 MB/s eta 0:00:11\n",
            "     - -------------------------------------- 0.5/16.3 MB 1.8 MB/s eta 0:00:09\n",
            "     - -------------------------------------- 0.7/16.3 MB 2.3 MB/s eta 0:00:07\n",
            "     -- ------------------------------------- 0.9/16.3 MB 2.6 MB/s eta 0:00:06\n",
            "     -- ------------------------------------- 1.1/16.3 MB 2.8 MB/s eta 0:00:06\n",
            "     --- ------------------------------------ 1.3/16.3 MB 2.9 MB/s eta 0:00:06\n",
            "     --- ------------------------------------ 1.4/16.3 MB 2.9 MB/s eta 0:00:06\n",
            "     --- ------------------------------------ 1.6/16.3 MB 3.1 MB/s eta 0:00:05\n",
            "     ---- ----------------------------------- 1.8/16.3 MB 3.2 MB/s eta 0:00:05\n",
            "     ---- ----------------------------------- 2.0/16.3 MB 3.2 MB/s eta 0:00:05\n",
            "     ---- ----------------------------------- 2.0/16.3 MB 3.2 MB/s eta 0:00:05\n",
            "     ----- ---------------------------------- 2.2/16.3 MB 3.0 MB/s eta 0:00:05\n",
            "     ----- ---------------------------------- 2.3/16.3 MB 3.0 MB/s eta 0:00:05\n",
            "     ------ --------------------------------- 2.5/16.3 MB 3.1 MB/s eta 0:00:05\n",
            "     ------ --------------------------------- 2.8/16.3 MB 3.2 MB/s eta 0:00:05\n",
            "     ------- -------------------------------- 3.0/16.3 MB 3.3 MB/s eta 0:00:05\n",
            "     ------- -------------------------------- 3.2/16.3 MB 3.4 MB/s eta 0:00:04\n",
            "     -------- ------------------------------- 3.4/16.3 MB 3.4 MB/s eta 0:00:04\n",
            "     -------- ------------------------------- 3.5/16.3 MB 3.3 MB/s eta 0:00:04\n",
            "     --------- ------------------------------ 3.7/16.3 MB 3.4 MB/s eta 0:00:04\n",
            "     --------- ------------------------------ 3.9/16.3 MB 3.4 MB/s eta 0:00:04\n",
            "     ---------- ----------------------------- 4.1/16.3 MB 3.5 MB/s eta 0:00:04\n",
            "     ---------- ----------------------------- 4.3/16.3 MB 3.5 MB/s eta 0:00:04\n",
            "     ---------- ----------------------------- 4.5/16.3 MB 3.6 MB/s eta 0:00:04\n",
            "     ----------- ---------------------------- 4.5/16.3 MB 3.4 MB/s eta 0:00:04\n",
            "     ----------- ---------------------------- 4.5/16.3 MB 3.3 MB/s eta 0:00:04\n",
            "     ----------- ---------------------------- 4.8/16.3 MB 3.4 MB/s eta 0:00:04\n",
            "     ------------ --------------------------- 5.1/16.3 MB 3.5 MB/s eta 0:00:04\n",
            "     ------------- -------------------------- 5.4/16.3 MB 3.6 MB/s eta 0:00:04\n",
            "     ------------- -------------------------- 5.4/16.3 MB 3.6 MB/s eta 0:00:04\n",
            "     -------------- ------------------------- 5.9/16.3 MB 3.7 MB/s eta 0:00:03\n",
            "     -------------- ------------------------- 6.1/16.3 MB 3.7 MB/s eta 0:00:03\n",
            "     --------------- ------------------------ 6.2/16.3 MB 3.7 MB/s eta 0:00:03\n",
            "     --------------- ------------------------ 6.4/16.3 MB 3.7 MB/s eta 0:00:03\n",
            "     --------------- ------------------------ 6.5/16.3 MB 3.7 MB/s eta 0:00:03\n",
            "     ---------------- ----------------------- 6.8/16.3 MB 3.7 MB/s eta 0:00:03\n",
            "     ----------------- ---------------------- 7.1/16.3 MB 3.8 MB/s eta 0:00:03\n",
            "     ----------------- ---------------------- 7.2/16.3 MB 3.8 MB/s eta 0:00:03\n",
            "     ----------------- ---------------------- 7.2/16.3 MB 3.7 MB/s eta 0:00:03\n",
            "     ----------------- ---------------------- 7.3/16.3 MB 3.6 MB/s eta 0:00:03\n",
            "     ------------------ --------------------- 7.5/16.3 MB 3.7 MB/s eta 0:00:03\n",
            "     ------------------ --------------------- 7.7/16.3 MB 3.7 MB/s eta 0:00:03\n",
            "     ------------------- -------------------- 7.8/16.3 MB 3.7 MB/s eta 0:00:03\n",
            "     ------------------- -------------------- 8.0/16.3 MB 3.6 MB/s eta 0:00:03\n",
            "     ------------------- -------------------- 8.1/16.3 MB 3.6 MB/s eta 0:00:03\n",
            "     -------------------- ------------------- 8.3/16.3 MB 3.6 MB/s eta 0:00:03\n",
            "     -------------------- ------------------- 8.3/16.3 MB 3.6 MB/s eta 0:00:03\n",
            "     -------------------- ------------------- 8.5/16.3 MB 3.6 MB/s eta 0:00:03\n",
            "     --------------------- ------------------ 8.6/16.3 MB 3.6 MB/s eta 0:00:03\n",
            "     --------------------- ------------------ 8.8/16.3 MB 3.5 MB/s eta 0:00:03\n",
            "     --------------------- ------------------ 8.9/16.3 MB 3.5 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 8.9/16.3 MB 3.5 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 8.9/16.3 MB 3.5 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 9.0/16.3 MB 3.4 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 9.1/16.3 MB 3.4 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 9.2/16.3 MB 3.4 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 9.3/16.3 MB 3.3 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 9.5/16.3 MB 3.3 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 9.6/16.3 MB 3.3 MB/s eta 0:00:02\n",
            "     ----------------------- ---------------- 9.7/16.3 MB 3.3 MB/s eta 0:00:02\n",
            "     ------------------------ --------------- 10.0/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ------------------------ --------------- 10.1/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ------------------------- -------------- 10.2/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ------------------------- -------------- 10.5/16.3 MB 3.5 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 10.7/16.3 MB 3.5 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 10.8/16.3 MB 3.5 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 10.8/16.3 MB 3.5 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 11.0/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 11.2/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 11.3/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 11.4/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 11.5/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 11.6/16.3 MB 3.3 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 11.8/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 12.0/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 12.2/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 12.4/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 12.4/16.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 12.9/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 12.9/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 12.9/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 13.2/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 13.4/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 13.6/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 13.8/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 13.9/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 14.2/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 14.4/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 14.6/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 14.7/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 14.9/16.3 MB 3.5 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 15.1/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 15.3/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 15.3/16.3 MB 3.4 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 15.3/16.3 MB 3.3 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 15.5/16.3 MB 3.3 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 15.7/16.3 MB 3.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------  15.9/16.3 MB 3.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------  16.0/16.3 MB 3.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------  16.1/16.3 MB 3.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------  16.1/16.3 MB 3.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------  16.2/16.3 MB 3.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------  16.3/16.3 MB 3.1 MB/s eta 0:00:01\n",
            "     ---------------------------------------  16.3/16.3 MB 3.1 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 16.3/16.3 MB 3.0 MB/s eta 0:00:00\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy nltk --user\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c_L-aldtkrB",
        "outputId": "c92ab86a-f1b1-44ba-80a5-e3b60d2cb3c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 1. IMPORTS\n",
        "# ============================================================\n",
        "\n",
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import random\n",
        "# from numba import cuda\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"DEVICE:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2rjV_WtJE0_",
        "outputId": "dbe9a49d-ca8c-4e61-d15e-0ce5931fb799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train examples: 29000\n",
            "Val examples: 1014\n",
            "Test examples: 1071\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 2. LOAD DATA (TRAIN / VAL / TEST)\n",
        "# ============================================================\n",
        "\n",
        "def load_file(path):\n",
        "    with open(path, \"r\", encoding=\"utf8\") as f:\n",
        "        return [line.strip() for line in f]\n",
        "\n",
        "# train_en = load_file(\"/content/train.en\")\n",
        "# train_fr = load_file(\"/content/train.fr\")\n",
        "\n",
        "# val_en = load_file(\"/content/val.en\")\n",
        "# val_fr = load_file(\"/content/val.fr\")\n",
        "\n",
        "# test_en = load_file(\"/content/test.en\")\n",
        "# test_fr = load_file(\"/content/test.fr\")\n",
        "\n",
        "train_en = load_file(\"./data/train.en\")\n",
        "train_fr = load_file(\"./data/train.fr\")\n",
        "\n",
        "val_en = load_file(\"./data/val.en\")\n",
        "val_fr = load_file(\"./data/val.fr\")\n",
        "\n",
        "test_en = load_file(\"./data/test.en\")\n",
        "test_fr = load_file(\"./data/test.fr\")\n",
        "\n",
        "print(\"Train examples:\", len(train_en))\n",
        "print(\"Val examples:\", len(val_en))\n",
        "print(\"Test examples:\", len(test_en))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "biwtBbHyK-xZ"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 3. TOKENIZATION (spaCy)\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "def en_tokenizer(text):\n",
        "    return [tok.text.lower() for tok in nlp_en.tokenizer(text)]\n",
        "def fr_tokenizer(text):\n",
        "    return [tok.text.lower() for tok in nlp_fr.tokenizer(text)]\n",
        "\n",
        "train_en_tok = [en_tokenizer(s) for s in train_en]\n",
        "train_fr_tok = [fr_tokenizer(s) for s in train_fr]\n",
        "\n",
        "val_en_tok = [en_tokenizer(s) for s in val_en]\n",
        "val_fr_tok = [fr_tokenizer(s) for s in val_fr]\n",
        "\n",
        "test_en_tok = [en_tokenizer(s) for s in test_en]\n",
        "test_fr_tok = [fr_tokenizer(s) for s in test_fr]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-dQoFk3uW-mq"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 4. BUILD VOCAB\n",
        "# ============================================================\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "SPECIAL_TOKENS = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, tokens, max_size=10000):\n",
        "        self.freq = Counter(tokens)\n",
        "        most_common = self.freq.most_common(max_size)\n",
        "\n",
        "        # word2idx\n",
        "        self.itos = SPECIAL_TOKENS + [w for w, _ in most_common]\n",
        "        self.stoi = {w:i for i, w in enumerate(self.itos)}\n",
        "\n",
        "    def numericalize(self, tokens):\n",
        "        return [self.stoi.get(t, self.stoi[\"<unk>\"]) for t in tokens]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "en_vocab = Vocab(tok for sent in train_en_tok for tok in sent)\n",
        "fr_vocab = Vocab(tok for sent in train_fr_tok for tok in sent)\n",
        "\n",
        "PAD_IDX = fr_vocab.stoi[\"<pad>\"]\n",
        "SOS_IDX = fr_vocab.stoi[\"<sos>\"]\n",
        "EOS_IDX = fr_vocab.stoi[\"<eos>\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3aXkGj5CagMq"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 5. DATASET + DATALOADER\n",
        "# ============================================================\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, en_data, fr_data, vocab_en, vocab_fr):\n",
        "        self.en = en_data\n",
        "        self.fr = fr_data\n",
        "        self.vocab_en = vocab_en\n",
        "        self.vocab_fr = vocab_fr\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.en)\n",
        "\n",
        "    # def numericalize(self, tokens, vocab):\n",
        "    #     return [vocab[\"<sos>\"]] + [vocab[t] for t in tokens] + [vocab[\"<eos>\"]]\n",
        "\n",
        "    # def __getitem__(self, idx):\n",
        "    #     src_num = self.numericalize(self.src[idx], self.src_vocab)\n",
        "    #     trg_num = self.numericalize(self.trg[idx], self.trg_vocab)\n",
        "    #     return torch.tensor(src_num), torch.tensor(trg_num)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        en_tokens = [\"<sos>\"] + self.en[idx] + [\"<eos>\"]\n",
        "        fr_tokens = [\"<sos>\"] + self.fr[idx] + [\"<eos>\"]\n",
        "\n",
        "        en_ids = self.vocab_en.numericalize(en_tokens)\n",
        "        fr_ids = self.vocab_fr.numericalize(fr_tokens)\n",
        "\n",
        "        return torch.tensor(en_ids), torch.tensor(fr_ids)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    en_batch, fr_batch = zip(*batch)\n",
        "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
        "    fr_batch = pad_sequence(fr_batch, padding_value=PAD_IDX)\n",
        "    return en_batch, fr_batch\n",
        "\n",
        "\n",
        "train_ds = TranslationDataset(train_en_tok, train_fr_tok, en_vocab, fr_vocab)\n",
        "val_ds = TranslationDataset(val_en_tok, val_fr_tok, en_vocab, fr_vocab)\n",
        "test_ds = TranslationDataset(test_en_tok, test_fr_tok, en_vocab, fr_vocab)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iBKoX7BLcpDe"
      },
      "outputs": [],
      "source": [
        "# # ============================================================\n",
        "# # 6. ENCODER - DECODER MODEL\n",
        "# # ============================================================\n",
        "\n",
        "# class Encoder(nn.Module):\n",
        "#     def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2, dropout=0.3):\n",
        "#         super().__init__()\n",
        "#         self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "#         self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
        "#                             num_layers=num_layers,\n",
        "#                             dropout=dropout)\n",
        "\n",
        "#     def forward(self, src):\n",
        "#         embedded = self.embedding(src)\n",
        "#         outputs, (hidden, cell) = self.lstm(embedded)\n",
        "#         return hidden, cell\n",
        "\n",
        "\n",
        "# class Decoder(nn.Module):\n",
        "#     def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2, dropout=0.3):\n",
        "#         super().__init__()\n",
        "#         self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "#         self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
        "#                             num_layers=num_layers,\n",
        "#                             dropout=dropout)\n",
        "#         self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "#     def forward(self, input, hidden, cell):\n",
        "#         input = input.unsqueeze(0)\n",
        "#         embedded = self.embedding(input)\n",
        "#         output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "#         prediction = self.fc(output.squeeze(0))\n",
        "#         return prediction, hidden, cell\n",
        "\n",
        "\n",
        "# class Seq2Seq(nn.Module):\n",
        "#     def __init__(self, encoder, decoder):\n",
        "#         super().__init__()\n",
        "#         self.encoder = encoder\n",
        "#         self.decoder = decoder\n",
        "\n",
        "#     def forward(self, src, trg, teacher_forcing=0.3):\n",
        "#         batch_size = trg.size(1)\n",
        "#         max_len = trg.size(0)\n",
        "#         vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "#         outputs = torch.zeros(max_len, batch_size, vocab_size).to(src.device)\n",
        "\n",
        "#         hidden, cell = self.encoder(src)\n",
        "#         input_token = trg[0, :]\n",
        "\n",
        "#         for t in range(1, max_len):\n",
        "#             output, hidden, cell = self.decoder(input_token, hidden, cell)\n",
        "#             outputs[t] = output\n",
        "#             best = output.argmax(1)\n",
        "\n",
        "#             input_token = trg[t] if random.random() < teacher_forcing else best\n",
        "\n",
        "#         return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zVBzDNJjua9Q"
      },
      "outputs": [],
      "source": [
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "        \"\"\"\n",
        "        decoder_hidden: [num_layers, batch, hidden]\n",
        "        encoder_outputs: [src_len, batch, hidden]\n",
        "        \"\"\"\n",
        "        # lấy hidden của layer cuối: [batch, hidden]\n",
        "        decoder_hidden = decoder_hidden[-1].unsqueeze(2)  # [batch, hidden, 1]\n",
        "\n",
        "        # Score = encoder_output · decoder_hidden\n",
        "        # encoder_outputs: [src_len, batch, hidden]\n",
        "        # sau permute:    [batch, src_len, hidden]\n",
        "        scores = torch.bmm(\n",
        "            encoder_outputs.permute(1,0,2),\n",
        "            decoder_hidden\n",
        "        ).squeeze(2)  # [batch, src_len]\n",
        "\n",
        "        attn_weights = torch.softmax(scores, dim=1)  # [batch, src_len]\n",
        "\n",
        "        return attn_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M1q1zuDzua9Q"
      },
      "outputs": [],
      "source": [
        "# class Encoder(nn.Module):\n",
        "#     def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2, dropout=0.5):\n",
        "#         super().__init__()\n",
        "#         self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "#         self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
        "#                             num_layers=num_layers,\n",
        "#                             dropout=dropout, bidirectional = True)\n",
        "\n",
        "#     def forward(self, src):\n",
        "#         embedded = self.embedding(src)\n",
        "#         outputs, (hidden, cell) = self.lstm(embedded)\n",
        "#         return outputs, hidden, cell   # trả về tất cả hidden states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ABDwimu5rTNC"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
        "                            num_layers=num_layers,\n",
        "                            dropout=dropout, bidirectional=True)\n",
        "\n",
        "        # ⚡ reduce 1024 → 512\n",
        "        self.fc_reduce = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        # reduce dimension\n",
        "        outputs = self.fc_reduce(outputs)\n",
        "\n",
        "        return outputs, hidden, cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f3LO5MzKua9R"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
        "                            num_layers=num_layers,\n",
        "                            dropout=dropout)\n",
        "\n",
        "        self.attention = LuongAttention(hidden_dim)\n",
        "\n",
        "        # combine context + decoder hidden\n",
        "        self.fc_concat = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
        "        input_token = input_token.unsqueeze(0)\n",
        "        embedded = self.embedding(input_token)\n",
        "\n",
        "        lstm_output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        lstm_output = lstm_output.squeeze(0)  # [batch, hidden]\n",
        "\n",
        "        # =========== Luong Attention ============\n",
        "        attn_weights = self.attention(hidden, encoder_outputs)  # [batch, src_len]\n",
        "\n",
        "        # context vector = sum(attn * encoder_outputs)\n",
        "        context = torch.bmm(\n",
        "            attn_weights.unsqueeze(1),       # [batch, 1, src_len]\n",
        "            encoder_outputs.permute(1,0,2)   # [batch, src_len, hidden]\n",
        "        ).squeeze(1)  # [batch, hidden]\n",
        "\n",
        "        # concat context + output\n",
        "        combined = torch.cat((lstm_output, context), dim=1)  # [batch, 2*hidden]\n",
        "        combined = torch.tanh(self.fc_concat(combined))      # [batch, hidden]\n",
        "\n",
        "        # final prediction\n",
        "        prediction = self.fc_out(combined)  # [batch, vocab]\n",
        "\n",
        "        return prediction, hidden, cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bgKWHzfIua9R"
      },
      "outputs": [],
      "source": [
        "# class Seq2Seq(nn.Module):\n",
        "#     def __init__(self, encoder, decoder):\n",
        "#         super().__init__()\n",
        "#         self.encoder = encoder\n",
        "#         self.decoder = decoder\n",
        "\n",
        "#     def forward(self, src, trg, teacher_forcing=0.3):\n",
        "#         batch_size = trg.size(1)\n",
        "#         max_len = trg.size(0)\n",
        "#         vocab_size = self.decoder.fc_out.out_features\n",
        "\n",
        "#         outputs = torch.zeros(max_len, batch_size, vocab_size).to(src.device)\n",
        "\n",
        "#         encoder_outputs, hidden, cell = self.encoder(src)\n",
        "#         input_token = trg[0, :]\n",
        "\n",
        "#         for t in range(1, max_len):\n",
        "#             output, hidden, cell = self.decoder(\n",
        "#                 input_token, hidden, cell, encoder_outputs\n",
        "#             )\n",
        "\n",
        "#             outputs[t] = output\n",
        "#             best = output.argmax(1)\n",
        "\n",
        "#             input_token = trg[t] if random.random() < teacher_forcing else best\n",
        "\n",
        "#         return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LJgXIUiJrDaE"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def _merge_bidir(self, h):\n",
        "        # h: [num_layers*2, batch, hidden]\n",
        "        return (h[0::2] + h[1::2]) / 2\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing=0.3):\n",
        "        batch_size = trg.size(1)\n",
        "        max_len = trg.size(0)\n",
        "        vocab_size = self.decoder.fc_out.out_features\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, vocab_size).to(src.device)\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "\n",
        "        # 🔥 GỘP 2 HƯỚNG → 1 HƯỚNG ⭐\n",
        "        hidden = self._merge_bidir(hidden)\n",
        "        cell   = self._merge_bidir(cell)\n",
        "\n",
        "        input_token = trg[0, :]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden, cell = self.decoder(\n",
        "                input_token, hidden, cell, encoder_outputs\n",
        "            )\n",
        "\n",
        "            outputs[t] = output\n",
        "            best = output.argmax(1)\n",
        "\n",
        "            input_token = trg[t] if random.random() < teacher_forcing else best\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAPoE3mOf0V7",
        "outputId": "41c41755-a995-477a-fea6-ddc68da0f06b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 2/907 [00:03<28:01,  1.86s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 46\u001b[0m\n\u001b[0;32m     42\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(src, trg)\n\u001b[0;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     45\u001b[0m                  trg[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 46\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     49\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    624\u001b[0m     )\n\u001b[1;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    842\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    843\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# # ============================================================\n",
        "# # 7. TRAINING + VALIDATION + EARLY STOPPING\n",
        "# # ============================================================\n",
        "\n",
        "input_dim = len(en_vocab)\n",
        "output_dim = len(fr_vocab)\n",
        "\n",
        "encoder = Encoder(input_dim, 256, 512).to(device)\n",
        "decoder = Decoder(output_dim, 256, 512).to(device)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for src, trg in loader:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            outputs = model(src, trg, teacher_forcing=0)\n",
        "            loss = criterion(outputs[1:].reshape(-1, outputs.size(-1)),\n",
        "                             trg[1:].reshape(-1))\n",
        "            total += loss.item()\n",
        "    return total / len(loader)\n",
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "best_val = float(\"inf\")\n",
        "patience = 3\n",
        "wait = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, trg in tqdm(train_loader):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(src, trg)\n",
        "\n",
        "        loss = criterion(outputs[1:].reshape(-1, outputs.size(-1)),\n",
        "                         trg[1:].reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "    val_loss = evaluate(model, val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Train={train_loss:.4f} | Val={val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        wait = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(\"Saved best model\")\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmW9W00XjCbs"
      },
      "outputs": [],
      "source": [
        "# def translate(sentence):\n",
        "#     model.eval()\n",
        "\n",
        "#     # tokenize\n",
        "#     tokens = en_tokenizer(sentence)\n",
        "\n",
        "#     # tạo vector số hóa đúng chuẩn\n",
        "#     ids = (\n",
        "#         [en_vocab.stoi[\"<sos>\"]] +\n",
        "#         [en_vocab.stoi.get(t, en_vocab.stoi[\"<unk>\"]) for t in tokens] +\n",
        "#         [en_vocab.stoi[\"<eos>\"]]\n",
        "#     )\n",
        "\n",
        "#     src = torch.tensor(ids).unsqueeze(1).to(device)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         hidden, cell = model.encoder(src)\n",
        "\n",
        "#     # token đầu tiên đầu ra\n",
        "#     input_tok = torch.tensor([fr_vocab.stoi[\"<sos>\"]]).to(device)\n",
        "#     outputs = []\n",
        "\n",
        "#     for _ in range(50):\n",
        "#         with torch.no_grad():\n",
        "#             pred, hidden, cell = model.decoder(input_tok, hidden, cell)\n",
        "\n",
        "#         top_id = pred.argmax(1).item()\n",
        "\n",
        "#         if top_id == fr_vocab.stoi[\"<eos>\"]:\n",
        "#             break\n",
        "\n",
        "#         outputs.append(top_id)\n",
        "#         input_tok = torch.tensor([top_id]).to(device)\n",
        "\n",
        "#     return \" \".join(fr_vocab.itos[i] for i in outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_dim = len(en_vocab)\n",
        "output_dim = len(fr_vocab)\n",
        "\n",
        "encoder = Encoder(input_dim, 256, 512).to(device)\n",
        "decoder = Decoder(output_dim, 256, 512).to(device)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-kDApZKny8gv"
      },
      "outputs": [],
      "source": [
        "def translate(sentence, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # tokenize câu tiếng Anh\n",
        "    tokens = en_tokenizer(sentence)\n",
        "\n",
        "    # chuyển sang ID\n",
        "    ids = (\n",
        "        [en_vocab.stoi[\"<sos>\"]] +\n",
        "        [en_vocab.stoi.get(t, en_vocab.stoi[\"<unk>\"]) for t in tokens] +\n",
        "        [en_vocab.stoi[\"<eos>\"]]\n",
        "    )\n",
        "\n",
        "    src = torch.tensor(ids).unsqueeze(1).to(device)   # shape: [seq_len, 1]\n",
        "\n",
        "    # ---- RUN ENCODER ----\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src)\n",
        "\n",
        "    # bắt đầu decoder bằng token <sos>\n",
        "    input_tok = torch.tensor([fr_vocab.stoi[\"<sos>\"]]).to(device)\n",
        "\n",
        "    outputs = []\n",
        "\n",
        "    # ---- RUN DECODER LOOP ----\n",
        "    for _ in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            pred, hidden, cell = model.decoder(\n",
        "                input_tok,\n",
        "                hidden,\n",
        "                cell,\n",
        "                encoder_outputs   # <<<< QUAN TRỌNG\n",
        "            )\n",
        "\n",
        "        top_id = pred.argmax(1).item()\n",
        "\n",
        "        if top_id == fr_vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "        outputs.append(top_id)\n",
        "        input_tok = torch.tensor([top_id]).to(device)\n",
        "\n",
        "    # chuyển ID → từ\n",
        "    return \" \".join(fr_vocab.itos[i] for i in outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2vt0EoijRwm3"
      },
      "outputs": [],
      "source": [
        "# def translate_beam(sentence, max_len=50, beam_size=3):\n",
        "#     model.eval()\n",
        "\n",
        "#     # tokenize câu tiếng Anh\n",
        "#     tokens = en_tokenizer(sentence)\n",
        "\n",
        "#     # chuyển sang ID\n",
        "#     ids = (\n",
        "#         [en_vocab.stoi[\"<sos>\"]] +\n",
        "#         [en_vocab.stoi.get(t, en_vocab.stoi[\"<unk>\"]) for t in tokens] +\n",
        "#         [en_vocab.stoi[\"<eos>\"]]\n",
        "#     )\n",
        "\n",
        "#     src = torch.tensor(ids).unsqueeze(1).to(device)  # [seq_len, 1]\n",
        "\n",
        "#     # ---- RUN ENCODER ----\n",
        "#     with torch.no_grad():\n",
        "#         encoder_outputs, hidden, cell = model.encoder(src)\n",
        "\n",
        "#     # beam = list of (sequence_ids, hidden, cell, score_log_prob)\n",
        "#     beam = [([fr_vocab.stoi[\"<sos>\"]], hidden, cell, 0.0)]\n",
        "\n",
        "#     for _ in range(max_len):\n",
        "#         new_beam = []\n",
        "\n",
        "#         for seq, h, c, score in beam:\n",
        "#             input_tok = torch.tensor([seq[-1]]).to(device)\n",
        "\n",
        "#             with torch.no_grad():\n",
        "#                 pred, h_new, c_new = model.decoder(input_tok, h, c, encoder_outputs)\n",
        "\n",
        "#             log_probs = torch.log_softmax(pred, dim=1).squeeze(0)  # [vocab_size]\n",
        "\n",
        "#             # lấy top k token\n",
        "#             top_log_probs, top_ids = torch.topk(log_probs, beam_size)\n",
        "\n",
        "#             for log_p, tok_id in zip(top_log_probs.tolist(), top_ids.tolist()):\n",
        "#                 new_seq = seq + [tok_id]\n",
        "#                 new_score = score + log_p\n",
        "#                 new_beam.append((new_seq, h_new, c_new, new_score))\n",
        "\n",
        "#         # giữ lại beam_size sequences tốt nhất\n",
        "#         new_beam = sorted(new_beam, key=lambda x: x[3], reverse=True)[:beam_size]\n",
        "#         beam = new_beam\n",
        "\n",
        "#         # nếu tất cả beam đã gặp <eos>, dừng\n",
        "#         if all(seq[-1] == fr_vocab.stoi[\"<eos>\"] for seq, _, _, _ in beam):\n",
        "#             break\n",
        "\n",
        "#     # chọn sequence có score cao nhất\n",
        "#     best_seq = beam[0][0]\n",
        "\n",
        "#     # loại bỏ <sos> và cắt đến <eos>\n",
        "#     if fr_vocab.stoi[\"<eos>\"] in best_seq:\n",
        "#         eos_idx = best_seq.index(fr_vocab.stoi[\"<eos>\"])\n",
        "#         best_seq = best_seq[1:eos_idx]\n",
        "#     else:\n",
        "#         best_seq = best_seq[1:]\n",
        "\n",
        "#     return \" \".join(fr_vocab.itos[i] for i in best_seq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bsUgUgWCw01E"
      },
      "outputs": [],
      "source": [
        "def translate_beam(sentence, max_len=50, beam_size=3):\n",
        "    model.eval()\n",
        "\n",
        "    # tokenize câu tiếng Anh\n",
        "    tokens = en_tokenizer(sentence)\n",
        "\n",
        "    # chuyển sang ID\n",
        "    ids = (\n",
        "        [en_vocab.stoi[\"<sos>\"]] +\n",
        "        [en_vocab.stoi.get(t, en_vocab.stoi[\"<unk>\"]) for t in tokens] +\n",
        "        [en_vocab.stoi[\"<eos>\"]]\n",
        "    )\n",
        "\n",
        "    src = torch.tensor(ids).unsqueeze(1).to(device)  # [seq_len, 1]\n",
        "\n",
        "    # ---- RUN ENCODER ----\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src)\n",
        "\n",
        "        # 🔥 merge bidirectional hidden/cell\n",
        "        def merge_bidir(h):\n",
        "            return (h[0::2] + h[1::2]) / 2\n",
        "\n",
        "        hidden = merge_bidir(hidden)\n",
        "        cell   = merge_bidir(cell)\n",
        "\n",
        "    # beam = list of (sequence_ids, hidden, cell, score_log_prob)\n",
        "    beam = [([fr_vocab.stoi[\"<sos>\"]], hidden, cell, 0.0)]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        new_beam = []\n",
        "\n",
        "        for seq, h, c, score in beam:\n",
        "            input_tok = torch.tensor([seq[-1]]).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pred, h_new, c_new = model.decoder(input_tok, h, c, encoder_outputs)\n",
        "\n",
        "            log_probs = torch.log_softmax(pred, dim=1).squeeze(0)  # [vocab_size]\n",
        "\n",
        "            # lấy top k token\n",
        "            top_log_probs, top_ids = torch.topk(log_probs, beam_size)\n",
        "\n",
        "            for log_p, tok_id in zip(top_log_probs.tolist(), top_ids.tolist()):\n",
        "                new_seq = seq + [tok_id]\n",
        "                new_score = score + log_p\n",
        "                new_beam.append((new_seq, h_new, c_new, new_score))\n",
        "\n",
        "        # giữ lại beam_size sequences tốt nhất\n",
        "        new_beam = sorted(new_beam, key=lambda x: x[3], reverse=True)[:beam_size]\n",
        "        beam = new_beam\n",
        "\n",
        "        # nếu tất cả beam đã gặp <eos>, dừng\n",
        "        if all(seq[-1] == fr_vocab.stoi[\"<eos>\"] for seq, _, _, _ in beam):\n",
        "            break\n",
        "\n",
        "    # chọn sequence có score cao nhất\n",
        "    best_seq = beam[0][0]\n",
        "\n",
        "    # loại bỏ <sos> và cắt đến <eos>\n",
        "    if fr_vocab.stoi[\"<eos>\"] in best_seq:\n",
        "        eos_idx = best_seq.index(fr_vocab.stoi[\"<eos>\"])\n",
        "        best_seq = best_seq[1:eos_idx]\n",
        "    else:\n",
        "        best_seq = best_seq[1:]\n",
        "\n",
        "    return \" \".join(fr_vocab.itos[i] for i in best_seq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuSoBh6c4KzY",
        "outputId": "791e99db-6b16-4e93-a9ba-febcd75eb6b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corpus BLEU on Test = 0.3121401146591142\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def evaluate_bleu():\n",
        "    references = []   # dạng: [[ref_tokens], [ref_tokens], ...]\n",
        "    hypotheses = []   # dạng: [pred_tokens, pred_tokens, ...]\n",
        "\n",
        "    for en, fr in zip(test_en_tok, test_fr_tok):\n",
        "        # input cho model là chuỗi tiếng Anh\n",
        "        pred = translate_beam(\" \".join(en))\n",
        "\n",
        "        # BLEU yêu cầu:\n",
        "        #   - ref: list các câu tham chiếu → mỗi câu phải bọc trong 1 list\n",
        "        #   - hyp: list các câu dự đoán tokenized\n",
        "        references.append([fr])\n",
        "        hypotheses.append(pred.split())\n",
        "\n",
        "    score = corpus_bleu(\n",
        "        references,\n",
        "        hypotheses,\n",
        "        weights=(0.25, 0.25, 0.25, 0.25)\n",
        "    )\n",
        "    return score\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_model_31211943.pth\"))\n",
        "bleu = evaluate_bleu()\n",
        "print(\"Corpus BLEU on Test =\", bleu)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwwrZrR9Ndrl",
        "outputId": "00cc951f-3f95-4659-9ddd-8fb2ec0ea290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1\n",
            "EN (Original) : a young man participates in a career while the subject who records it smiles .\n",
            "FR (Reference): un jeune homme participe à une course pendant que le sujet qui le filme sourit .\n",
            "FR (Predicted): un jeune homme participe à un tracteur tandis que le qu' il est en train de sourit .\n",
            "------------------------------------------------------------\n",
            "Example 2\n",
            "EN (Original) : the man is scratching the back of his neck while looking for a book in a book store .\n",
            "FR (Reference): l' homme se gratte l' arrière du cou tout en cherchant un livre dans une librairie .\n",
            "FR (Predicted): l' homme a le l' arrière d' son cou , en train de regarder un livre dans un livre .\n",
            "------------------------------------------------------------\n",
            "Example 3\n",
            "EN (Original) : a person wearing goggles and a hat is sled riding .\n",
            "FR (Reference): une personne portant des lunettes de protection et un chapeau fait de la luge .\n",
            "FR (Predicted): une personne avec des lunettes et une casquette fait du roller .\n",
            "------------------------------------------------------------\n",
            "Example 4\n",
            "EN (Original) : a girl in a pink coat and flowered goloshes sledding down a hill .\n",
            "FR (Reference): une fille avec une veste rose et des galoches à fleurs descend le long d' une colline en luge .\n",
            "FR (Predicted): une fille en manteau rose et fleurs à fleurs faisant une luge sur une colline .\n",
            "------------------------------------------------------------\n",
            "Example 5\n",
            "EN (Original) : three girls are standing in front of a window of a building .\n",
            "FR (Reference): trois filles se tiennent devant la fenêtre d' un bâtiment .\n",
            "FR (Predicted): trois filles sont debout devant une fenêtre d' un bâtiment .\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Số câu muốn thử\n",
        "num_examples = 5\n",
        "\n",
        "for i in range(num_examples):\n",
        "    # Lấy câu gốc tiếng Anh\n",
        "    en_sentence = \" \".join(test_en_tok[i])\n",
        "\n",
        "    # Dịch sang tiếng Pháp\n",
        "    fr_pred = translate_beam(en_sentence, beam_size=3)\n",
        "\n",
        "    # Lấy câu tham chiếu tiếng Pháp\n",
        "    fr_ref = \" \".join(test_fr_tok[i])\n",
        "\n",
        "    # In ra kết quả\n",
        "    print(f\"Example {i+1}\")\n",
        "    print(\"EN (Original) :\", en_sentence)\n",
        "    print(\"FR (Reference):\", fr_ref)\n",
        "    print(\"FR (Predicted):\", fr_pred)\n",
        "    print(\"-\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
