{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doduyquy/NLP_Machine-Translation-LSTM/blob/main/Load_file_pth_and_translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52af59ba",
      "metadata": {
        "id": "52af59ba"
      },
      "source": [
        "# Load file checkpoint (pth)  và and translate (en --> fr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ad6fbf",
      "metadata": {
        "id": "e5ad6fbf"
      },
      "source": [
        "# 1. Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "96761269",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96761269",
        "outputId": "9249fb70-a2ee-4e6b-c01d-5f17762aaeb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Model exists: True\n",
            "Dataset folder exists: True\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Kiểm tra file model tồn tại\n",
        "import os\n",
        "model_path = \"/content/drive/My Drive/021.SGU/01.Subjects/NLP/[best_model]0-316_en-fr_Luong-Attention+Beam.pth\"\n",
        "dataset_path = \"/content/drive/My Drive/021.SGU/01.Subjects/NLP/Dataset/\"\n",
        "\n",
        "print(f\"Model exists: {os.path.exists(model_path)}\")\n",
        "print(f\"Dataset folder exists: {os.path.exists(dataset_path)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "317b2b18",
      "metadata": {
        "id": "317b2b18"
      },
      "source": [
        "# 2. Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2ebf1ec1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ebf1ec1",
        "outputId": "fcfffe78-0d81-48bf-c0b6-cc7968391d3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy --quiet\n",
        "!python -m spacy download en_core_web_sm --quiet\n",
        "!python -m spacy download fr_core_news_sm --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f247fbd1",
      "metadata": {
        "id": "f247fbd1"
      },
      "source": [
        "# 3. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cfaa3489",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfaa3489",
        "outputId": "e715bea9-51da-4303-9aa7-7496073bf920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "256c0a00",
      "metadata": {
        "id": "256c0a00"
      },
      "source": [
        "# 4. Define Constants and Special Tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "111ccfe7",
      "metadata": {
        "id": "111ccfe7"
      },
      "outputs": [],
      "source": [
        "# Special tokens\n",
        "SPECIAL_TOKENS_CONST = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
        "VOCAB_MAX_SIZE_CONST = 10000\n",
        "\n",
        "# Model hyperparameters (giống với lúc train)\n",
        "LSTM_NUM_LAYERS = 2\n",
        "LSTM_DROPOUT = 0.3\n",
        "LSTM_EMBED_DIM = 256\n",
        "LSTM_HIDDEN_DIM = 512\n",
        "\n",
        "# Paths\n",
        "MODEL_PATH = model_path\n",
        "DATASET_PATH = dataset_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b95ea073",
      "metadata": {
        "id": "b95ea073"
      },
      "source": [
        "# 5. Load Tokenizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23b8db95",
      "metadata": {
        "id": "23b8db95"
      },
      "outputs": [],
      "source": [
        "# Load spacy's pre-trained models\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "def en_tokenizer(text):\n",
        "    \"\"\"Tokenize English text\"\"\"\n",
        "    return [tok.text.lower() for tok in nlp_en.tokenizer(text)]\n",
        "\n",
        "def fr_tokenizer(text):\n",
        "    \"\"\"Tokenize French text\"\"\"\n",
        "    return [tok.text.lower() for tok in nlp_fr.tokenizer(text)]\n",
        "\n",
        "# Test tokenizers\n",
        "print(\"EN tokenizer test:\", en_tokenizer(\"Hello, how are you?\"))\n",
        "print(\"FR tokenizer test:\", fr_tokenizer(\"Bonjour, comment allez-vous?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db5a36ff",
      "metadata": {
        "id": "db5a36ff"
      },
      "source": [
        "# 6. Build Vocabulary Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc503bf3",
      "metadata": {
        "id": "bc503bf3"
      },
      "outputs": [],
      "source": [
        "class Vocab:\n",
        "    def __init__(self, tokens, max_size=VOCAB_MAX_SIZE_CONST):\n",
        "        # Get dictionary: {word, frequency}\n",
        "        self.freq = Counter(tokens)\n",
        "        # Get only max_size most common words\n",
        "        most_common = self.freq.most_common(max_size)\n",
        "\n",
        "        # Set list of SPECIAL_TOKENS and most_common words\n",
        "        self.itos = SPECIAL_TOKENS_CONST + [word for word, _ in most_common]\n",
        "        # Set dict for each item\n",
        "        self.stoi = {word: idx for idx, word in enumerate(self.itos)}\n",
        "\n",
        "    def numericalize(self, tokens):\n",
        "        \"\"\"Convert tokens to indices\"\"\"\n",
        "        return [self.stoi.get(tok, self.stoi.get('<unk>')) for tok in tokens]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b1c05e1",
      "metadata": {
        "id": "6b1c05e1"
      },
      "source": [
        "# 7. Load Training Data and Build Vocabularies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "207f240c",
      "metadata": {
        "id": "207f240c"
      },
      "outputs": [],
      "source": [
        "def load_file(path):\n",
        "    \"\"\"Load text file and return list of lines\"\"\"\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        return [line.strip() for line in file]\n",
        "\n",
        "# Load training data\n",
        "train_en = load_file(f\"{DATASET_PATH}/train.en\")\n",
        "train_fr = load_file(f\"{DATASET_PATH}/train.fr\")\n",
        "\n",
        "print(f\"Loaded {len(train_en)} English sentences\")\n",
        "print(f\"Loaded {len(train_fr)} French sentences\")\n",
        "\n",
        "# Tokenize training data\n",
        "print(\"\\nTokenizing training data...\")\n",
        "train_en_tok = [en_tokenizer(sentence) for sentence in train_en]\n",
        "train_fr_tok = [fr_tokenizer(sentence) for sentence in train_fr]\n",
        "print(\"Tokenization complete!\")\n",
        "\n",
        "# Build vocabularies\n",
        "print(\"\\nBuilding vocabularies...\")\n",
        "vocab_en = Vocab(tok for sentence in train_en_tok for tok in sentence)\n",
        "vocab_fr = Vocab(tok for sentence in train_fr_tok for tok in sentence)\n",
        "\n",
        "print(f\"English vocabulary size: {len(vocab_en)}\")\n",
        "print(f\"French vocabulary size: {len(vocab_fr)}\")\n",
        "\n",
        "# Get special token indices\n",
        "PAD_IDX = vocab_fr.stoi.get('<pad>')\n",
        "SOS_IDX = vocab_fr.stoi.get('<sos>')\n",
        "EOS_IDX = vocab_fr.stoi.get('<eos>')\n",
        "\n",
        "print(f\"\\nSpecial token indices:\")\n",
        "print(f\"  PAD_IDX: {PAD_IDX}\")\n",
        "print(f\"  SOS_IDX: {SOS_IDX}\")\n",
        "print(f\"  EOS_IDX: {EOS_IDX}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad8912f2",
      "metadata": {
        "id": "ad8912f2"
      },
      "source": [
        "# 8. Define Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b76a77d5",
      "metadata": {
        "id": "b76a77d5"
      },
      "outputs": [],
      "source": [
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "        \"\"\"\n",
        "        decoder_hidden: [num_layers, batch, hidden]\n",
        "        encoder_outputs: [src_len, batch, hidden]\n",
        "        \"\"\"\n",
        "        # Get hidden of last layer: [batch, hidden]\n",
        "        decoder_hidden = decoder_hidden[-1].unsqueeze(2)  # [batch, hidden, 1]\n",
        "\n",
        "        # Score = encoder_output · decoder_hidden\n",
        "        scores = torch.bmm(\n",
        "            encoder_outputs.permute(1, 0, 2),\n",
        "            decoder_hidden\n",
        "        ).squeeze(2)  # [batch, src_len]\n",
        "\n",
        "        attn_weights = torch.softmax(scores, dim=1)  # [batch, src_len]\n",
        "\n",
        "        return attn_weights\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=LSTM_NUM_LAYERS, dropout=LSTM_DROPOUT):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
        "                            num_layers=num_layers,\n",
        "                            dropout=dropout)\n",
        "\n",
        "    def forward(self, src, src_lens):\n",
        "        embedded = self.embedding(src)\n",
        "\n",
        "        # Pack padded sequence\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embedded,\n",
        "            src_lens.cpu(),\n",
        "            enforce_sorted=True\n",
        "        )\n",
        "        # LSTM forward\n",
        "        packed_outputs, (hidden, cell) = self.lstm(packed)\n",
        "        # Unpack\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
        "\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=LSTM_NUM_LAYERS, dropout=LSTM_DROPOUT):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
        "                            num_layers=num_layers,\n",
        "                            dropout=dropout)\n",
        "        # Attention module\n",
        "        self.attention = LuongAttention(hidden_dim)\n",
        "        # Fully connected - input size is hidden_dim * 2 (context + decoder output)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.embedding(input)\n",
        "\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "\n",
        "        # Apply attention\n",
        "        attn_weights = self.attention(hidden, encoder_outputs)\n",
        "\n",
        "        # Context vector\n",
        "        context = torch.bmm(\n",
        "            attn_weights.unsqueeze(1),\n",
        "            encoder_outputs.permute(1, 0, 2)\n",
        "        ).squeeze(1)\n",
        "\n",
        "        # Concatenate context and decoder output\n",
        "        combined = torch.cat([output.squeeze(0), context], dim=1)\n",
        "\n",
        "        # Prediction\n",
        "        prediction = self.fc(combined)\n",
        "\n",
        "        return prediction, hidden, cell, attn_weights\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg, src_lens, teacher_forcing=0.5):\n",
        "        batch_size = trg.size(1)\n",
        "        max_len = trg.size(0)\n",
        "        vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, vocab_size).to(src.device)\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(src, src_lens)\n",
        "\n",
        "        input_token = trg[0, :]\n",
        "\n",
        "        for timestep in range(1, max_len):\n",
        "            output, hidden, cell, _ = self.decoder(input_token, hidden, cell, encoder_outputs)\n",
        "            outputs[timestep] = output\n",
        "            input_token = output.argmax(1)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e110ba81",
      "metadata": {
        "id": "e110ba81"
      },
      "source": [
        "# 9. Initialize and Load Model Weights\n",
        "\n",
        "Tạo model instances và load weights từ file .pth đã lưu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "545195a7",
      "metadata": {
        "id": "545195a7"
      },
      "outputs": [],
      "source": [
        "# Get vocabulary sizes\n",
        "input_dim = len(vocab_en)\n",
        "output_dim = len(vocab_fr)\n",
        "\n",
        "print(f\"Input dimension (EN vocab): {input_dim}\")\n",
        "print(f\"Output dimension (FR vocab): {output_dim}\")\n",
        "\n",
        "# Create model instances\n",
        "encoder = Encoder(\n",
        "    vocab_size=input_dim,\n",
        "    embed_dim=LSTM_EMBED_DIM,\n",
        "    hidden_dim=LSTM_HIDDEN_DIM,\n",
        "    num_layers=LSTM_NUM_LAYERS\n",
        ").to(device)\n",
        "\n",
        "decoder = Decoder(\n",
        "    vocab_size=output_dim,\n",
        "    embed_dim=LSTM_EMBED_DIM,\n",
        "    hidden_dim=LSTM_HIDDEN_DIM,\n",
        "    num_layers=LSTM_NUM_LAYERS\n",
        ").to(device)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "# Load saved weights\n",
        "print(f\"\\nLoading model from: {MODEL_PATH}\")\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"[OK] Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b92f61e",
      "metadata": {
        "id": "8b92f61e"
      },
      "source": [
        "# 10. Define Translation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90c6a853",
      "metadata": {
        "id": "90c6a853"
      },
      "outputs": [],
      "source": [
        "def translate(sentence, max_len=50):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = en_tokenizer(sentence)\n",
        "\n",
        "    # Create token indices\n",
        "    ids = (\n",
        "        [vocab_en.stoi[\"<sos>\"]] +\n",
        "        [vocab_en.stoi.get(t, vocab_en.stoi[\"<unk>\"]) for t in tokens] +\n",
        "        [vocab_en.stoi[\"<eos>\"]]\n",
        "    )\n",
        "\n",
        "    src = torch.tensor(ids).unsqueeze(1).to(device)\n",
        "    src_lens = torch.tensor([len(ids)]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src, src_lens)\n",
        "\n",
        "    input_tok = torch.tensor([vocab_fr.stoi[\"<sos>\"]]).to(device)\n",
        "    outputs = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            pred, hidden, cell, _ = model.decoder(input_tok, hidden, cell, encoder_outputs)\n",
        "\n",
        "        top_id = pred.argmax(1).item()\n",
        "\n",
        "        if top_id == vocab_fr.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "        outputs.append(top_id)\n",
        "        input_tok = torch.tensor([top_id]).to(device)\n",
        "\n",
        "    return \" \".join(vocab_fr.itos[i] for i in outputs)\n",
        "\n",
        "\n",
        "def translate_beam(sentence, beam_width=5, max_len=50):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = en_tokenizer(sentence)\n",
        "\n",
        "    ids = (\n",
        "        [vocab_en.stoi[\"<sos>\"]] +\n",
        "        [vocab_en.stoi.get(t, vocab_en.stoi[\"<unk>\"]) for t in tokens] +\n",
        "        [vocab_en.stoi[\"<eos>\"]]\n",
        "    )\n",
        "\n",
        "    src = torch.tensor(ids).unsqueeze(1).to(device)\n",
        "    src_lens = torch.tensor([len(ids)]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src, src_lens)\n",
        "\n",
        "    # Initialize beam\n",
        "    beams = [(0.0, [vocab_fr.stoi[\"<sos>\"]], hidden, cell)]\n",
        "    completed_hypotheses = []\n",
        "\n",
        "    for step in range(max_len):\n",
        "        next_beams = []\n",
        "\n",
        "        for log_prob, tokens_seq, h, c in beams:\n",
        "            if tokens_seq[-1] == vocab_fr.stoi[\"<eos>\"]:\n",
        "                completed_hypotheses.append((log_prob, tokens_seq))\n",
        "                continue\n",
        "\n",
        "            input_tok = torch.tensor([tokens_seq[-1]]).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pred, h_new, c_new, _ = model.decoder(input_tok, h, c, encoder_outputs)\n",
        "                log_probs = torch.log_softmax(pred, dim=1)\n",
        "\n",
        "            top_log_probs, top_indices = torch.topk(log_probs[0], beam_width)\n",
        "\n",
        "            for token_log_prob, token_id in zip(top_log_probs, top_indices):\n",
        "                new_log_prob = log_prob + token_log_prob.item()\n",
        "                new_tokens = tokens_seq + [token_id.item()]\n",
        "                next_beams.append((new_log_prob, new_tokens, h_new, c_new))\n",
        "\n",
        "        next_beams.sort(key=lambda x: x[0], reverse=True)\n",
        "        beams = next_beams[:beam_width]\n",
        "\n",
        "        if not beams or all(tokens_seq[-1] == vocab_fr.stoi[\"<eos>\"] for _, tokens_seq, _, _ in beams):\n",
        "            break\n",
        "\n",
        "    for log_prob, tokens_seq, _, _ in beams:\n",
        "        completed_hypotheses.append((log_prob, tokens_seq))\n",
        "\n",
        "    if not completed_hypotheses:\n",
        "        return \"\"\n",
        "\n",
        "    completed_hypotheses.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_log_prob, best_tokens = completed_hypotheses[0]\n",
        "\n",
        "    output_tokens = [\n",
        "        vocab_fr.itos[idx]\n",
        "        for idx in best_tokens\n",
        "        if idx != vocab_fr.stoi[\"<sos>\"] and idx != vocab_fr.stoi[\"<eos>\"]\n",
        "    ]\n",
        "\n",
        "    return \" \".join(output_tokens)\n",
        "\n",
        "print(\"[OK] Translation functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e59d104",
      "metadata": {
        "id": "1e59d104"
      },
      "source": [
        "# 11. Test Translation with Random Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8875b46a",
      "metadata": {
        "id": "8875b46a"
      },
      "outputs": [],
      "source": [
        "# Compare different beam widths\n",
        "test_sentence = \"child sits on street on a busy street . \"\n",
        "\n",
        "print(f\"English: {test_sentence}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"Greedy:    {translate(test_sentence)}\")\n",
        "\n",
        "for bw in [3, 5]:\n",
        "    result = translate_beam(test_sentence, beam_width=bw)\n",
        "    print(f\"Beam-{bw:2d}:   {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51900e4e",
      "metadata": {
        "id": "51900e4e"
      },
      "source": [
        "# The end."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4yuEAETBMejP"
      },
      "id": "4yuEAETBMejP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}